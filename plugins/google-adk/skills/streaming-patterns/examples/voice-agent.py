"""
Complete voice agent implementation with ADK bidi-streaming.

Demonstrates:
- Audio input/output streaming
- Session resumption
- Context window compression
- Transcription
- Interruption handling

CRITICAL SECURITY: No hardcoded API keys.
Set GOOGLE_API_KEY environment variable before running.
"""

import os
import asyncio
from google.adk.agents import Agent, LiveRequestQueue
from google.adk.agents.run_config import RunConfig, StreamingMode
from google.genai import types


async def main():
    """Run voice agent with bidi-streaming."""

    # SECURITY: Read API key from environment
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError(
            "GOOGLE_API_KEY environment variable not set. "
            "Get your key from: https://aistudio.google.com/apikey"
        )

    # Create voice agent
    agent = Agent(
        name="voice-assistant",
        model="gemini-2.0-flash-multimodal-live",
        system_instruction=(
            "You are a helpful voice assistant. "
            "Speak naturally and conversationally. "
            "Be concise but friendly."
        )
    )

    # Configure for production voice streaming
    run_config = RunConfig(
        # Audio output (voice responses)
        response_modalities=["AUDIO"],
        streaming_mode=StreamingMode.BIDI,

        # Enable session resumption (automatic reconnection)
        session_resumption=types.SessionResumptionConfig(),

        # Enable context compression (unlimited conversation)
        context_window_compression=types.ContextWindowCompressionConfig(
            trigger_tokens=100000,
            sliding_window=types.SlidingWindow(target_tokens=80000)
        ),

        # Voice configuration
        speech_config=types.SpeechConfig(
            voice_config=types.VoiceConfig(
                prebuilt_voice_config=types.PrebuiltVoiceConfig(
                    voice_name="Puck"  # Male voice
                )
            )
        ),

        # Enable transcription (both directions)
        audio_transcription_config=types.AudioTranscriptionConfig(
            transcribe_input_audio=True,
            transcribe_output_audio=True
        ),

        # Save audio for quality assurance
        save_live_blob=True,

        # Production metadata
        custom_metadata={
            "environment": "production",
            "version": "1.0.0"
        }
    )

    # Create request queue
    request_queue = LiveRequestQueue()

    # Start audio input task (background)
    audio_input_task = asyncio.create_task(
        stream_microphone_audio(request_queue)
    )

    print("üé§ Voice Assistant Started")
    print("Speak into your microphone...")
    print("Press Ctrl+C to stop\n")

    try:
        # Process agent responses
        async for event in agent.run_live(request_queue, run_config=run_config):
            # Handle interruptions
            if event.interrupted:
                print("\n‚ö†Ô∏è  [Interrupted]")
                stop_audio_playback()

            # Handle errors
            if event.error:
                print(f"\n‚ùå Error: {event.error}")

            # Handle server content
            if event.server_content:
                # User input transcription
                if event.server_content.user_input_transcript:
                    user_text = event.server_content.user_input_transcript.text
                    print(f"\nüë§ You: {user_text}")

                # Agent response
                if event.server_content.model_turn:
                    for part in event.server_content.model_turn.parts:
                        # Audio output
                        if part.inline_data:
                            play_audio(part.inline_data.data)

                        # Agent transcript
                        if part.text:
                            print(f"ü§ñ Agent: {part.text}")

                # Turn complete
                if event.server_content.turn_complete:
                    print("")  # Blank line for readability

    except KeyboardInterrupt:
        print("\n\nüëã Stopping voice assistant...")
    finally:
        # Clean up
        audio_input_task.cancel()
        print("‚úÖ Voice assistant stopped")


async def stream_microphone_audio(queue: LiveRequestQueue):
    """
    Stream audio from microphone to queue.

    In production, replace with actual microphone capture.
    """
    try:
        # This is a placeholder - replace with actual microphone input
        # For example using pyaudio, sounddevice, or similar
        print("üì° [Audio input streaming started]")

        while True:
            # Capture audio chunk from microphone
            # audio_chunk = capture_microphone_chunk()
            audio_chunk = b"\x00" * 1024  # Placeholder: 1KB silence

            # Create audio input message
            audio_input = types.LiveClientRealtimeInput(
                media_chunks=[
                    types.LiveClientRealtimeInputMediaChunk(
                        data=audio_chunk,
                        mime_type="audio/pcm"  # PCM16, 16kHz, mono
                    )
                ]
            )

            # Enqueue audio
            await queue.put(audio_input)

            # Adjust timing based on chunk size
            await asyncio.sleep(0.1)  # 100ms chunks

    except asyncio.CancelledError:
        print("üì° [Audio input streaming stopped]")


def play_audio(audio_bytes: bytes):
    """
    Play audio bytes through speakers.

    In production, replace with actual audio playback.
    """
    # Placeholder - replace with actual audio playback
    # For example using pyaudio, sounddevice, or similar
    pass
    # print(f"üîä [Playing {len(audio_bytes)} bytes of audio]")


def stop_audio_playback():
    """Stop current audio playback."""
    # Placeholder - implement audio stop logic
    pass


# Example: Actual Microphone Capture (commented out - requires pyaudio)
"""
import pyaudio

def capture_microphone_chunk():
    '''Capture audio chunk from microphone.'''
    CHUNK = 1024
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 16000

    p = pyaudio.PyAudio()
    stream = p.open(
        format=FORMAT,
        channels=CHANNELS,
        rate=RATE,
        input=True,
        frames_per_buffer=CHUNK
    )

    try:
        data = stream.read(CHUNK)
        return data
    finally:
        stream.close()
        p.terminate()
"""


# Example: Actual Audio Playback (commented out - requires pyaudio)
"""
import pyaudio

def play_audio(audio_bytes: bytes):
    '''Play audio bytes through speakers.'''
    CHUNK = 1024
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RATE = 24000  # Gemini outputs 24kHz

    p = pyaudio.PyAudio()
    stream = p.open(
        format=FORMAT,
        channels=CHANNELS,
        rate=RATE,
        output=True
    )

    try:
        stream.write(audio_bytes)
    finally:
        stream.close()
        p.terminate()
"""


if __name__ == "__main__":
    asyncio.run(main())


# SETUP INSTRUCTIONS:
"""
1. Install dependencies:
   pip install google-adk

2. Set API key:
   export GOOGLE_API_KEY=your_google_api_key_here

3. For actual audio (optional):
   pip install pyaudio
   # Then uncomment the pyaudio examples above

4. Run:
   python voice-agent.py

5. Platform selection (optional):
   # Use Google AI Studio (default)
   export GOOGLE_GENAI_USE_VERTEXAI=FALSE

   # Use Vertex AI
   export GOOGLE_GENAI_USE_VERTEXAI=TRUE
"""


# FEATURES DEMONSTRATED:
"""
‚úÖ Audio input streaming (microphone)
‚úÖ Audio output streaming (speakers)
‚úÖ Session resumption (auto-reconnect)
‚úÖ Context window compression (unlimited conversation)
‚úÖ Transcription (both directions)
‚úÖ Interruption handling
‚úÖ Error handling
‚úÖ Production-ready configuration
‚úÖ Metadata tracking
‚úÖ Audio blob saving
"""
