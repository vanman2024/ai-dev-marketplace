{
  "name": "ml-training",
  "version": "1.0.0",
  "description": "Machine learning training and inference pipeline using cloud GPUs (Modal, Lambda Labs, RunPod) with HuggingFace ecosystem - no local GPU required",
  "author": {
    "name": "AI Dev Marketplace",
    "email": "builder@example.com"
  },
  "license": "MIT",
  "keywords": [
    "machine-learning",
    "training",
    "inference",
    "cloud-gpu",
    "modal",
    "lambda-labs",
    "runpod",
    "huggingface",
    "transformers",
    "peft",
    "pytorch",
    "serverless"
  ],
  "type": "Framework"
}
